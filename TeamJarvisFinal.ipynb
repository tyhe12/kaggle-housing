{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0907962bb0457507ec70e80c5b310b05e0733e0acb39410aad0feb59d5741b43a",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from catboost import Pool, cv, CatBoostRegressor\n",
    "from scipy.special import boxcox1p\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LassoCV, Lasso, RidgeCV, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train_data['Training'] = 1\n",
    "test_data['Training'] = 0\n",
    "numerical_features = train_data.dtypes[train_data.dtypes != 'object'].index.values\n",
    "categorical_features = train_data.dtypes[train_data.dtypes == 'object'].index.values\n",
    "submit = ['SalePrice', 'Id']\n",
    "significant_columns_cat = ['Neighborhood', 'ExterQual', 'BsmtQual', 'KitchenQual', 'GarageFinish',\n",
    " 'FireplaceQu', 'Foundation', 'GarageType', 'BsmtFinType1', 'HeatingQC',\n",
    " 'MasVnrType', 'BsmtExposure', 'SaleCondition', 'Exterior1st', 'Exterior2nd',\n",
    " 'SaleType', 'MSZoning', 'HouseStyle', 'GarageQual', 'GarageCond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolQC  Fence MiscFeature MiscVal MoSold  \\\n",
       "0            Lvl    AllPub  ...    NaN    NaN         NaN       0      2   \n",
       "1            Lvl    AllPub  ...    NaN    NaN         NaN       0      5   \n",
       "2            Lvl    AllPub  ...    NaN    NaN         NaN       0      9   \n",
       "3            Lvl    AllPub  ...    NaN    NaN         NaN       0      2   \n",
       "4            Lvl    AllPub  ...    NaN    NaN         NaN       0     12   \n",
       "...          ...       ...  ...    ...    ...         ...     ...    ...   \n",
       "1455         Lvl    AllPub  ...    NaN    NaN         NaN       0      8   \n",
       "1456         Lvl    AllPub  ...    NaN  MnPrv         NaN       0      2   \n",
       "1457         Lvl    AllPub  ...    NaN  GdPrv        Shed    2500      5   \n",
       "1458         Lvl    AllPub  ...    NaN    NaN         NaN       0      4   \n",
       "1459         Lvl    AllPub  ...    NaN    NaN         NaN       0      6   \n",
       "\n",
       "     YrSold SaleType  SaleCondition  SalePrice  Training  \n",
       "0      2008       WD         Normal     208500         1  \n",
       "1      2007       WD         Normal     181500         1  \n",
       "2      2008       WD         Normal     223500         1  \n",
       "3      2006       WD        Abnorml     140000         1  \n",
       "4      2008       WD         Normal     250000         1  \n",
       "...     ...      ...            ...        ...       ...  \n",
       "1455   2007       WD         Normal     175000         1  \n",
       "1456   2010       WD         Normal     210000         1  \n",
       "1457   2010       WD         Normal     266500         1  \n",
       "1458   2010       WD         Normal     142125         1  \n",
       "1459   2008       WD         Normal     147500         1  \n",
       "\n",
       "[1459 rows x 82 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>...</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n      <th>Training</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>250000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1455</th>\n      <td>1456</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>62.0</td>\n      <td>7917</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>8</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>175000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>1457</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>85.0</td>\n      <td>13175</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>MnPrv</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>210000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1457</th>\n      <td>1458</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>66.0</td>\n      <td>9042</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>GdPrv</td>\n      <td>Shed</td>\n      <td>2500</td>\n      <td>5</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>266500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>1459</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>9717</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2010</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>142125</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1459</th>\n      <td>1460</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>75.0</td>\n      <td>9937</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>147500</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1459 rows Ã— 82 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "# preprocessing\n",
    "# remove outliers\n",
    "# LotFrontage > 300\n",
    "train_data.drop(train_data[train_data['LotFrontage']>300].index)\n",
    "# LotArea > 100000\n",
    "train_data.drop(train_data[train_data['LotArea']>100000].index)\n",
    "# BsmtFinSF1 > 4000\n",
    "train_data.drop(train_data[train_data['BsmtFinSF1']>4000].index)\n",
    "# GrLivArea > 4000\n",
    "train_data.drop(train_data[train_data['GrLivArea']>4500].index)\n",
    "# TotalBsmtSF > 5000\n",
    "train_data.drop(train_data[train_data['TotalBsmtSF']>5000].index)\n",
    "# OpenPorchSF > 500\n",
    "train_data.drop(train_data[train_data['OpenPorchSF']>500].index)\n",
    "# 1stFlrSF > 4000\n",
    "train_data.drop(train_data[train_data['1stFlrSF']>4000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat training and testing\n",
    "y = train_data['SalePrice']\n",
    "all_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# fill categoricals\n",
    "categoricals = all_data[categorical_features]\n",
    "categoricals['MSZoning'] = categoricals['MSZoning'].fillna(categoricals['MSZoning'].mode()[0])\n",
    "categoricals.fillna('None', inplace=True)\n",
    "all_data[categorical_features] = categoricals\n",
    "\n",
    "# fill in numeric\n",
    "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))\n",
    "all_data.fillna(0, inplace=True)\n",
    "\n",
    "# select significant columns\n",
    "significant_columns = [*significant_columns_cat, *numerical_features]\n",
    "all_data = all_data[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# convert non-categorical to categorical\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].apply(str)\n",
    "\n",
    "# add in more features\n",
    "all_data['TotalSF'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['Bathrooms'] = all_data['BsmtFullBath'] + all_data['FullBath'] + (all_data['BsmtHalfBath'] + all_data['HalfBath']) * 0.5\n",
    "all_data['QualSF'] = all_data['TotalSF'] * all_data['OverallQual']\n",
    "all_data['HasPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasRemod'] = (all_data['YearBuilt'] - all_data['YearRemodAdd']).apply(lambda x: 1 if x != 0 else 0)\n",
    "all_data['Has3SsnPorch'] = all_data['3SsnPorch'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasLowQualFin'] = all_data['LowQualFinSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['Age'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['IsNew'] = (all_data['YrSold'] - all_data['YearBuilt']).apply(lambda x: 1 if x == 0 else 0)\n",
    "all_data['TotalPorch'] = all_data['OpenPorchSF'] + all_data['EnclosedPorch'] + all_data['3SsnPorch'] + all_data['ScreenPorch']\n",
    "all_data['HasPorch'] = all_data['TotalPorch'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# binning\n",
    "all_data['OpenPorchSF'] = pd.cut(all_data['OpenPorchSF'], [0, 5, 100, 300, 1000], include_lowest=True, labels=False)\n",
    "all_data['OpenPorchSF'] = all_data['OpenPorchSF'].apply(str)\n",
    "all_data['EnclosedPorch'] = pd.cut(all_data['EnclosedPorch'], [0, 5, 100, 250, 1000], include_lowest=True, labels=False)\n",
    "all_data['EnclosedPorch'] = all_data['EnclosedPorch'].apply(str)\n",
    "all_data['ScreenPorch'] = pd.cut(all_data['ScreenPorch'], [0, 5, 200, 1000], include_lowest=True, labels=False)\n",
    "all_data['ScreenPorch'] = all_data['ScreenPorch'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping a few columns\n",
    "to_drop = ['MoSold', 'PoolArea', 'GarageYrBlt', '3SsnPorch', 'YearRemodAdd', 'LowQualFinSF']\n",
    "all_data.drop(columns=to_drop, inplace=True)\n",
    "# drop saleprice\n",
    "all_data.drop(columns='SalePrice', inplace=True)\n",
    "\n",
    "# redefine categoricals\n",
    "numerical_features = all_data.dtypes[all_data.dtypes != 'object'].index.values\n",
    "categorical_features = all_data.dtypes[all_data.dtypes == 'object'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features based on skewness\n",
    "skewness_cap = 2 # can change this number around a bit\n",
    "# define ignored features\n",
    "ignored_features = ['HasPool', 'HasGarage', 'HasRemod', 'Has3SsnPorch', 'HasLowQualFin', 'IsNew', 'HasPorch']\n",
    "# find skewness\n",
    "skewness = all_data[numerical_features].apply(lambda x: st.skew(x)).sort_values(ascending=False)\n",
    "skewness_features = skewness[abs(skewness) > skewness_cap].index\n",
    "skewness_features = [f for f in skewness_features if f not in ignored_features]\n",
    "# box-cox transform\n",
    "for col in skewness_features:\n",
    "    all_data[col] = boxcox1p(all_data[col], st.boxcox_normmax(all_data[col] + 1))\n",
    "\n",
    "# Show result\n",
    "# adjusted_skewness = all_data[skewness_features].apply(lambda x: st.skew(x))\n",
    "\n",
    "# skewness_compare = pd.DataFrame()\n",
    "# skewness_compare['Features'] = skewness_features\n",
    "# skewness_compare['Original'] = skewness[skewness_features].values\n",
    "# skewness_compare['Adjusted'] = adjusted_skewness.values\n",
    "# skewness_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process categoricals\n",
    "all_data = pd.get_dummies(data=all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up the dataset\n",
    "train_set = all_data.loc[all_data['Training'] == 1]\n",
    "test_set = all_data.loc[all_data['Training'] == 0]\n",
    "\n",
    "# obtain X & y\n",
    "\n",
    "y_log = np.log1p(y)\n",
    "target_y = y_log\n",
    "\n",
    "omit = ['SalePrice', 'Id', 'Training']\n",
    "X = train_set[[c for c in train_set.columns if c not in omit]]\n",
    "X_test = test_set[[c for c in test_set.columns if c not in omit]]\n",
    "\n",
    "# further split into validation set and training set\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X, target_y, test_size=0.1, random_state=27)\n",
    "eval_set = [(x_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True to run all CVs\n",
    "run_full_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lasso model and use cv to find best alpha\n",
    "alphas = np.arange(1e-5, 1e-2, 1e-5)\n",
    "if run_full_tuning:\n",
    "    lasso_reg = LassoCV(cv=5, \n",
    "        random_state=0, \n",
    "        max_iter=50000, \n",
    "        alphas=alphas).fit(X, target_y)\n",
    "    best_alpha = lasso_reg.alpha_ # Lasso alpha: 0.00042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ridge model and use cv to find best alpha\n",
    "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 20, 30, 50, 75, 100]\n",
    "if run_full_tuning:\n",
    "    ridge_reg = RidgeCV(cv=5, \n",
    "        alphas=ridge_alphas).fit(X, target_y)\n",
    "\n",
    "    best_ridge_alpha = ridge_reg.alpha_ # Ridge alpha: 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR CV Grid Search\n",
    "if run_full_tuning:\n",
    "    svr_model = SVR()\n",
    "\n",
    "    clf = GridSearchCV(svr_model,\n",
    "        {'C': [1, 5, 10, 20],\n",
    "        'epsilon': [0.1, 0.01, 0.001],\n",
    "        'gamma': [1, 0.1, 0.001, 0.0001, 0.00001]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_svr_c = clf.best_params_['C']\n",
    "    best_svr_epsilon = clf.best_params_['epsilon']\n",
    "    best_svr_gamma = clf.best_params_['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for xgb\n",
    "if False:\n",
    "    xgb_model = XGBRegressor(n_jobs=1, gamma=0, n_estimators=5000)\n",
    "    clf = GridSearchCV(xgb_model,\n",
    "        {'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 4, 5, 6]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_rate_xgb = clf.best_params_['learning_rate']\n",
    "    best_depth_xgb = clf.best_params_['max_depth']\n",
    "\n",
    "    xgb_model = XGBRegressor(n_jobs=1, gamma=0, n_estimators=5000, learning_rate=best_rate_xgb, max_depth=best_depth_xgb)\n",
    "    clf = GridSearchCV(xgb_model,\n",
    "        {'subsample': [0.5, 0.8, 1],\n",
    "        'colsample_bytree': [0.5, 0.8, 1]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_subsample_xgb = clf.best_params_['subsample']\n",
    "    best_colsample_bytree_xgb = clf.best_params_['colsample_bytree']\n",
    "\n",
    "    xgb_model = XGBRegressor(n_jobs=1, \n",
    "        gamma=0, \n",
    "        n_estimators=5000, \n",
    "        learning_rate=best_rate_xgb, \n",
    "        max_depth=best_depth_xgb,\n",
    "        subsample=best_subsample_xgb,\n",
    "        colsample_bytree=best_colsample_bytree_xgb)\n",
    "    clf = GridSearchCV(xgb_model,\n",
    "        {'reg_alpha': [0.5, 0.7, 0.9],\n",
    "        'reg_lambda': [0.5, 0.6, 0.8]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_alpha_xgb = clf.best_params_['reg_alpha']\n",
    "    best_lambda_xgb = clf.best_params_['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(random_state=0, \n",
    "        max_iter=50000, \n",
    "        alpha=0.00042)) \n",
    "\n",
    "xgb = XGBRegressor(n_jobs=1, \n",
    "    gamma=0, \n",
    "    n_estimators=5000, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=3,\n",
    "    subsample=0.7,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.6,\n",
    "    scale_pos_weight=1,\n",
    "    min_child_weight=0,\n",
    "    random_state=27,\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7)\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(), Ridge(alpha=10))\n",
    "\n",
    "svr = make_pipeline(RobustScaler(), SVR(C=5, epsilon=0.001, gamma=0.0001))\n",
    "\n",
    "stacked = StackingCVRegressor(regressors=(lasso, xgb, ridge, svr),\n",
    "    meta_regressor=xgb,\n",
    "    use_features_in_secondary=True,\n",
    "    random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train models for training set and evaluate against the validation set\n",
    "if run_full_tuning:\n",
    "    lasso_train = lasso.fit(x_train, y_train)\n",
    "    ridge_train = ridge.fit(x_train, y_train)\n",
    "    svr_train = svr.fit(x_train, y_train)\n",
    "    xgb_train = xgb.fit(x_train, y_train, eval_set=eval_set, early_stopping_rounds=100, eval_metric='rmse')\n",
    "    stacked_train = stacked.fit(np.array(x_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all models\n",
    "def rmse(y1, y2):\n",
    "    return np.sqrt(metrics.mean_squared_error(y1, y2))\n",
    "\n",
    "if run_full_tuning:\n",
    "    pred_lasso = lasso_train.predict(x_validation)\n",
    "    pred_xgb = xgb_train.predict(x_validation)\n",
    "    pred_ridge = ridge_train.predict(x_validation)\n",
    "    pred_svr = svr_train.predict(x_validation)\n",
    "    pred_stacked = stacked_train.predict(np.array(x_validation))\n",
    "\n",
    "    min_error = 100\n",
    "    best_lasso_weight = 0\n",
    "    best_xgb_weight = 0\n",
    "    best_ridge_weight = 0\n",
    "    best_svr_weight = 0\n",
    "    best_stacked_weight = 0\n",
    "    count = 0\n",
    "\n",
    "    good_weights = pd.DataFrame(columns=['Lasso', 'XGB', 'Ridge', 'SVR', 'Stacked', 'Error'])\n",
    "\n",
    "    print('Start looking for good weight...')\n",
    "    for lasso_weight in np.arange(0, 1, 0.05):\n",
    "        xgb_weights = np.arange(0, 1 - lasso_weight, 0.05)\n",
    "        for xgb_weight in xgb_weights:\n",
    "            ridge_weights = np.arange(0, 1 - lasso_weight - xgb_weight, 0.05)\n",
    "            for ridge_weight in ridge_weights:\n",
    "                svr_weights = np.arange(0, 1 - lasso_weight - xgb_weight - ridge_weight, 0.05)\n",
    "                for svr_weight in svr_weights:\n",
    "                    stacked_weight = 1 - lasso_weight - xgb_weight - ridge_weight - svr_weight\n",
    "                    \n",
    "                    count = count + 1\n",
    "                    y_pred_val = (stacked_weight * pred_stacked + \n",
    "                        xgb_weight * pred_xgb + \n",
    "                        lasso_weight * pred_lasso + \n",
    "                        svr_weight * pred_svr + \n",
    "                        ridge_weight * pred_ridge)\n",
    "                    \n",
    "                    error = rmse(y_validation, y_pred_val)\n",
    "                    if error < 0.13: # error cap for a good combination\n",
    "                        good_weights = good_weights.append({\n",
    "                            'Lasso': lasso_weight,\n",
    "                            'XGB': xgb_weight,\n",
    "                            'Ridge': ridge_weight,\n",
    "                            'SVR': svr_weight,\n",
    "                            'Stacked': stacked_weight,\n",
    "                            'Error': error\n",
    "                            }, ignore_index=True)\n",
    "                    if error < min_error:\n",
    "                        print('Found better weighting at iteration:', count)\n",
    "                        print(min_error, '->', error)\n",
    "                        min_error = error\n",
    "                        best_lasso_weight = lasso_weight\n",
    "                        best_xgb_weight = xgb_weight\n",
    "                        best_svr_weight = svr_weight\n",
    "                        best_ridge_weight = ridge_weight\n",
    "                        best_stacked_weight = stacked_weight\n",
    "\n",
    "    print('Best Lasso Weight', best_lasso_weight)\n",
    "    print('Best XGB Weight', best_xgb_weight)\n",
    "    print('Best Stacked Weight', best_stacked_weight)\n",
    "    print('Best Ridge Weight', best_ridge_weight)\n",
    "    print('Best SVR Weight', best_svr_weight)\n",
    "\n",
    "    good_weights = good_weights.sort_values('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Lasso   XGB  Ridge   SVR  Stacked     Error\n",
       "8105   0.45  0.15   0.00  0.15     0.25  0.096759\n",
       "8052   0.45  0.10   0.00  0.15     0.30  0.096768\n",
       "7762   0.40  0.15   0.00  0.15     0.30  0.096790\n",
       "7708   0.40  0.10   0.00  0.20     0.30  0.096796\n",
       "8345   0.50  0.10   0.00  0.15     0.25  0.096806\n",
       "7807   0.40  0.20   0.00  0.15     0.25  0.096807\n",
       "7763   0.40  0.15   0.00  0.20     0.25  0.096812\n",
       "8382   0.50  0.15   0.00  0.10     0.25  0.096817\n",
       "8143   0.45  0.20   0.00  0.15     0.20  0.096820\n",
       "8053   0.45  0.10   0.00  0.20     0.25  0.096823\n",
       "8142   0.45  0.20   0.00  0.10     0.25  0.096830\n",
       "7998   0.45  0.05   0.00  0.20     0.30  0.096833\n",
       "8104   0.45  0.15   0.00  0.10     0.30  0.096837\n",
       "8300   0.50  0.05   0.00  0.15     0.30  0.096840\n",
       "8383   0.50  0.15   0.00  0.15     0.20  0.096841\n",
       "7707   0.40  0.10   0.00  0.15     0.35  0.096843\n",
       "7997   0.45  0.05   0.00  0.15     0.35  0.096846\n",
       "7771   0.40  0.15   0.05  0.15     0.25  0.096847\n",
       "7642   0.40  0.05   0.00  0.20     0.35  0.096850\n",
       "8344   0.50  0.10   0.00  0.10     0.30  0.096850"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Lasso</th>\n      <th>XGB</th>\n      <th>Ridge</th>\n      <th>SVR</th>\n      <th>Stacked</th>\n      <th>Error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8105</th>\n      <td>0.45</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.25</td>\n      <td>0.096759</td>\n    </tr>\n    <tr>\n      <th>8052</th>\n      <td>0.45</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.30</td>\n      <td>0.096768</td>\n    </tr>\n    <tr>\n      <th>7762</th>\n      <td>0.40</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.30</td>\n      <td>0.096790</td>\n    </tr>\n    <tr>\n      <th>7708</th>\n      <td>0.40</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>0.30</td>\n      <td>0.096796</td>\n    </tr>\n    <tr>\n      <th>8345</th>\n      <td>0.50</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.25</td>\n      <td>0.096806</td>\n    </tr>\n    <tr>\n      <th>7807</th>\n      <td>0.40</td>\n      <td>0.20</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.25</td>\n      <td>0.096807</td>\n    </tr>\n    <tr>\n      <th>7763</th>\n      <td>0.40</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>0.25</td>\n      <td>0.096812</td>\n    </tr>\n    <tr>\n      <th>8382</th>\n      <td>0.50</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.25</td>\n      <td>0.096817</td>\n    </tr>\n    <tr>\n      <th>8143</th>\n      <td>0.45</td>\n      <td>0.20</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.20</td>\n      <td>0.096820</td>\n    </tr>\n    <tr>\n      <th>8053</th>\n      <td>0.45</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>0.25</td>\n      <td>0.096823</td>\n    </tr>\n    <tr>\n      <th>8142</th>\n      <td>0.45</td>\n      <td>0.20</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.25</td>\n      <td>0.096830</td>\n    </tr>\n    <tr>\n      <th>7998</th>\n      <td>0.45</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>0.30</td>\n      <td>0.096833</td>\n    </tr>\n    <tr>\n      <th>8104</th>\n      <td>0.45</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.30</td>\n      <td>0.096837</td>\n    </tr>\n    <tr>\n      <th>8300</th>\n      <td>0.50</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.30</td>\n      <td>0.096840</td>\n    </tr>\n    <tr>\n      <th>8383</th>\n      <td>0.50</td>\n      <td>0.15</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.20</td>\n      <td>0.096841</td>\n    </tr>\n    <tr>\n      <th>7707</th>\n      <td>0.40</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.35</td>\n      <td>0.096843</td>\n    </tr>\n    <tr>\n      <th>7997</th>\n      <td>0.45</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.15</td>\n      <td>0.35</td>\n      <td>0.096846</td>\n    </tr>\n    <tr>\n      <th>7771</th>\n      <td>0.40</td>\n      <td>0.15</td>\n      <td>0.05</td>\n      <td>0.15</td>\n      <td>0.25</td>\n      <td>0.096847</td>\n    </tr>\n    <tr>\n      <th>7642</th>\n      <td>0.40</td>\n      <td>0.05</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>0.35</td>\n      <td>0.096850</td>\n    </tr>\n    <tr>\n      <th>8344</th>\n      <td>0.50</td>\n      <td>0.10</td>\n      <td>0.00</td>\n      <td>0.10</td>\n      <td>0.30</td>\n      <td>0.096850</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "good_weights.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "149\n",
      "[905]\tvalidation_0-rmse:0.14147\n",
      "[906]\tvalidation_0-rmse:0.14148\n",
      "[907]\tvalidation_0-rmse:0.14149\n",
      "[908]\tvalidation_0-rmse:0.14149\n",
      "[909]\tvalidation_0-rmse:0.14149\n",
      "[910]\tvalidation_0-rmse:0.14149\n",
      "[911]\tvalidation_0-rmse:0.14151\n",
      "[912]\tvalidation_0-rmse:0.14149\n",
      "[913]\tvalidation_0-rmse:0.14148\n",
      "[914]\tvalidation_0-rmse:0.14148\n",
      "[915]\tvalidation_0-rmse:0.14149\n",
      "[916]\tvalidation_0-rmse:0.14148\n",
      "[917]\tvalidation_0-rmse:0.14151\n",
      "[918]\tvalidation_0-rmse:0.14151\n",
      "[919]\tvalidation_0-rmse:0.14150\n",
      "[920]\tvalidation_0-rmse:0.14149\n",
      "[921]\tvalidation_0-rmse:0.14145\n",
      "[922]\tvalidation_0-rmse:0.14143\n",
      "[923]\tvalidation_0-rmse:0.14142\n",
      "[924]\tvalidation_0-rmse:0.14141\n",
      "[925]\tvalidation_0-rmse:0.14140\n",
      "[926]\tvalidation_0-rmse:0.14132\n",
      "[927]\tvalidation_0-rmse:0.14133\n",
      "[928]\tvalidation_0-rmse:0.14130\n",
      "[929]\tvalidation_0-rmse:0.14128\n",
      "[930]\tvalidation_0-rmse:0.14128\n",
      "[931]\tvalidation_0-rmse:0.14128\n",
      "[932]\tvalidation_0-rmse:0.14118\n",
      "[933]\tvalidation_0-rmse:0.14112\n",
      "[934]\tvalidation_0-rmse:0.14114\n",
      "[935]\tvalidation_0-rmse:0.14116\n",
      "[936]\tvalidation_0-rmse:0.14115\n",
      "[937]\tvalidation_0-rmse:0.14114\n",
      "[938]\tvalidation_0-rmse:0.14115\n",
      "[939]\tvalidation_0-rmse:0.14114\n",
      "[940]\tvalidation_0-rmse:0.14115\n",
      "[941]\tvalidation_0-rmse:0.14114\n",
      "[942]\tvalidation_0-rmse:0.14111\n",
      "[943]\tvalidation_0-rmse:0.14110\n",
      "[944]\tvalidation_0-rmse:0.14106\n",
      "[945]\tvalidation_0-rmse:0.14106\n",
      "[946]\tvalidation_0-rmse:0.14105\n",
      "[947]\tvalidation_0-rmse:0.14103\n",
      "[948]\tvalidation_0-rmse:0.14102\n",
      "[949]\tvalidation_0-rmse:0.14103\n",
      "[950]\tvalidation_0-rmse:0.14106\n",
      "[951]\tvalidation_0-rmse:0.14107\n",
      "[952]\tvalidation_0-rmse:0.14106\n",
      "[953]\tvalidation_0-rmse:0.14109\n",
      "[954]\tvalidation_0-rmse:0.14111\n",
      "[955]\tvalidation_0-rmse:0.14103\n",
      "[956]\tvalidation_0-rmse:0.14106\n",
      "[957]\tvalidation_0-rmse:0.14105\n",
      "[958]\tvalidation_0-rmse:0.14104\n",
      "[959]\tvalidation_0-rmse:0.14102\n",
      "[960]\tvalidation_0-rmse:0.14093\n",
      "[961]\tvalidation_0-rmse:0.14092\n",
      "[962]\tvalidation_0-rmse:0.14094\n",
      "[963]\tvalidation_0-rmse:0.14092\n",
      "[964]\tvalidation_0-rmse:0.14091\n",
      "[965]\tvalidation_0-rmse:0.14091\n",
      "[966]\tvalidation_0-rmse:0.14087\n",
      "[967]\tvalidation_0-rmse:0.14088\n",
      "[968]\tvalidation_0-rmse:0.14087\n",
      "[969]\tvalidation_0-rmse:0.14084\n",
      "[970]\tvalidation_0-rmse:0.14083\n",
      "[971]\tvalidation_0-rmse:0.14080\n",
      "[972]\tvalidation_0-rmse:0.14081\n",
      "[973]\tvalidation_0-rmse:0.14082\n",
      "[974]\tvalidation_0-rmse:0.14080\n",
      "[975]\tvalidation_0-rmse:0.14079\n",
      "[976]\tvalidation_0-rmse:0.14080\n",
      "[977]\tvalidation_0-rmse:0.14079\n",
      "[978]\tvalidation_0-rmse:0.14081\n",
      "[979]\tvalidation_0-rmse:0.14079\n",
      "[980]\tvalidation_0-rmse:0.14081\n",
      "[981]\tvalidation_0-rmse:0.14078\n",
      "[982]\tvalidation_0-rmse:0.14077\n",
      "[983]\tvalidation_0-rmse:0.14071\n",
      "[984]\tvalidation_0-rmse:0.14072\n",
      "[985]\tvalidation_0-rmse:0.14072\n",
      "[986]\tvalidation_0-rmse:0.14073\n",
      "[987]\tvalidation_0-rmse:0.14073\n",
      "[988]\tvalidation_0-rmse:0.14071\n",
      "[989]\tvalidation_0-rmse:0.14073\n",
      "[990]\tvalidation_0-rmse:0.14074\n",
      "[991]\tvalidation_0-rmse:0.14075\n",
      "[992]\tvalidation_0-rmse:0.14078\n",
      "[993]\tvalidation_0-rmse:0.14077\n",
      "[994]\tvalidation_0-rmse:0.14076\n",
      "[995]\tvalidation_0-rmse:0.14076\n",
      "[996]\tvalidation_0-rmse:0.14076\n",
      "[997]\tvalidation_0-rmse:0.14077\n",
      "[998]\tvalidation_0-rmse:0.14078\n",
      "[999]\tvalidation_0-rmse:0.14075\n",
      "[1000]\tvalidation_0-rmse:0.14075\n",
      "[1001]\tvalidation_0-rmse:0.14076\n",
      "[1002]\tvalidation_0-rmse:0.14076\n",
      "[1003]\tvalidation_0-rmse:0.14077\n",
      "[1004]\tvalidation_0-rmse:0.14079\n",
      "[1005]\tvalidation_0-rmse:0.14078\n",
      "[1006]\tvalidation_0-rmse:0.14081\n",
      "[1007]\tvalidation_0-rmse:0.14078\n",
      "[1008]\tvalidation_0-rmse:0.14080\n",
      "[1009]\tvalidation_0-rmse:0.14083\n",
      "[1010]\tvalidation_0-rmse:0.14081\n",
      "[1011]\tvalidation_0-rmse:0.14082\n",
      "[1012]\tvalidation_0-rmse:0.14083\n",
      "[1013]\tvalidation_0-rmse:0.14082\n",
      "[1014]\tvalidation_0-rmse:0.14080\n",
      "[1015]\tvalidation_0-rmse:0.14080\n",
      "[1016]\tvalidation_0-rmse:0.14072\n",
      "[1017]\tvalidation_0-rmse:0.14075\n",
      "[1018]\tvalidation_0-rmse:0.14071\n",
      "[1019]\tvalidation_0-rmse:0.14068\n",
      "[1020]\tvalidation_0-rmse:0.14066\n",
      "[1021]\tvalidation_0-rmse:0.14069\n",
      "[1022]\tvalidation_0-rmse:0.14067\n",
      "[1023]\tvalidation_0-rmse:0.14068\n",
      "[1024]\tvalidation_0-rmse:0.14067\n",
      "[1025]\tvalidation_0-rmse:0.14070\n",
      "[1026]\tvalidation_0-rmse:0.14070\n",
      "[1027]\tvalidation_0-rmse:0.14068\n",
      "[1028]\tvalidation_0-rmse:0.14065\n",
      "[1029]\tvalidation_0-rmse:0.14065\n",
      "[1030]\tvalidation_0-rmse:0.14064\n",
      "[1031]\tvalidation_0-rmse:0.14065\n",
      "[1032]\tvalidation_0-rmse:0.14063\n",
      "[1033]\tvalidation_0-rmse:0.14064\n",
      "[1034]\tvalidation_0-rmse:0.14064\n",
      "[1035]\tvalidation_0-rmse:0.14064\n",
      "[1036]\tvalidation_0-rmse:0.14062\n",
      "[1037]\tvalidation_0-rmse:0.14063\n",
      "[1038]\tvalidation_0-rmse:0.14062\n",
      "[1039]\tvalidation_0-rmse:0.14064\n",
      "[1040]\tvalidation_0-rmse:0.14062\n",
      "[1041]\tvalidation_0-rmse:0.14061\n",
      "[1042]\tvalidation_0-rmse:0.14063\n",
      "[1043]\tvalidation_0-rmse:0.14060\n",
      "[1044]\tvalidation_0-rmse:0.14059\n",
      "[1045]\tvalidation_0-rmse:0.14059\n",
      "[1046]\tvalidation_0-rmse:0.14062\n",
      "[1047]\tvalidation_0-rmse:0.14062\n",
      "[1048]\tvalidation_0-rmse:0.14062\n",
      "[1049]\tvalidation_0-rmse:0.14064\n",
      "[1050]\tvalidation_0-rmse:0.14065\n",
      "[1051]\tvalidation_0-rmse:0.14063\n",
      "[1052]\tvalidation_0-rmse:0.14064\n",
      "[1053]\tvalidation_0-rmse:0.14064\n",
      "[1054]\tvalidation_0-rmse:0.14069\n",
      "[1055]\tvalidation_0-rmse:0.14067\n",
      "[1056]\tvalidation_0-rmse:0.14065\n",
      "[1057]\tvalidation_0-rmse:0.14066\n",
      "[1058]\tvalidation_0-rmse:0.14069\n",
      "[1059]\tvalidation_0-rmse:0.14068\n",
      "[1060]\tvalidation_0-rmse:0.14067\n",
      "[1061]\tvalidation_0-rmse:0.14064\n",
      "[1062]\tvalidation_0-rmse:0.14065\n",
      "[1063]\tvalidation_0-rmse:0.14065\n",
      "[1064]\tvalidation_0-rmse:0.14065\n",
      "[1065]\tvalidation_0-rmse:0.14064\n",
      "[1066]\tvalidation_0-rmse:0.14055\n",
      "[1067]\tvalidation_0-rmse:0.14057\n",
      "[1068]\tvalidation_0-rmse:0.14057\n",
      "[1069]\tvalidation_0-rmse:0.14056\n",
      "[1070]\tvalidation_0-rmse:0.14058\n",
      "[1071]\tvalidation_0-rmse:0.14060\n",
      "[1072]\tvalidation_0-rmse:0.14059\n",
      "[1073]\tvalidation_0-rmse:0.14058\n",
      "[1074]\tvalidation_0-rmse:0.14060\n",
      "[1075]\tvalidation_0-rmse:0.14059\n",
      "[1076]\tvalidation_0-rmse:0.14060\n",
      "[1077]\tvalidation_0-rmse:0.14059\n",
      "[1078]\tvalidation_0-rmse:0.14057\n",
      "[1079]\tvalidation_0-rmse:0.14057\n",
      "[1080]\tvalidation_0-rmse:0.14057\n",
      "[1081]\tvalidation_0-rmse:0.14057\n",
      "[1082]\tvalidation_0-rmse:0.14059\n",
      "[1083]\tvalidation_0-rmse:0.14060\n",
      "[1084]\tvalidation_0-rmse:0.14062\n",
      "[1085]\tvalidation_0-rmse:0.14061\n",
      "[1086]\tvalidation_0-rmse:0.14061\n",
      "[1087]\tvalidation_0-rmse:0.14059\n",
      "[1088]\tvalidation_0-rmse:0.14060\n",
      "[1089]\tvalidation_0-rmse:0.14061\n",
      "[1090]\tvalidation_0-rmse:0.14060\n",
      "[1091]\tvalidation_0-rmse:0.14055\n",
      "[1092]\tvalidation_0-rmse:0.14055\n",
      "[1093]\tvalidation_0-rmse:0.14055\n",
      "[1094]\tvalidation_0-rmse:0.14052\n",
      "[1095]\tvalidation_0-rmse:0.14052\n",
      "[1096]\tvalidation_0-rmse:0.14054\n",
      "[1097]\tvalidation_0-rmse:0.14056\n",
      "[1098]\tvalidation_0-rmse:0.14054\n",
      "[1099]\tvalidation_0-rmse:0.14056\n",
      "[1100]\tvalidation_0-rmse:0.14053\n",
      "[1101]\tvalidation_0-rmse:0.14052\n",
      "[1102]\tvalidation_0-rmse:0.14053\n",
      "[1103]\tvalidation_0-rmse:0.14052\n",
      "[1104]\tvalidation_0-rmse:0.14054\n",
      "[1105]\tvalidation_0-rmse:0.14053\n",
      "[1106]\tvalidation_0-rmse:0.14053\n",
      "[1107]\tvalidation_0-rmse:0.14055\n",
      "[1108]\tvalidation_0-rmse:0.14055\n",
      "[1109]\tvalidation_0-rmse:0.14054\n",
      "[1110]\tvalidation_0-rmse:0.14053\n",
      "[1111]\tvalidation_0-rmse:0.14055\n",
      "[1112]\tvalidation_0-rmse:0.14055\n",
      "[1113]\tvalidation_0-rmse:0.14052\n",
      "[1114]\tvalidation_0-rmse:0.14050\n",
      "[1115]\tvalidation_0-rmse:0.14050\n",
      "[1116]\tvalidation_0-rmse:0.14049\n",
      "[1117]\tvalidation_0-rmse:0.14047\n",
      "[1118]\tvalidation_0-rmse:0.14045\n",
      "[1119]\tvalidation_0-rmse:0.14043\n",
      "[1120]\tvalidation_0-rmse:0.14041\n",
      "[1121]\tvalidation_0-rmse:0.14042\n",
      "[1122]\tvalidation_0-rmse:0.14043\n",
      "[1123]\tvalidation_0-rmse:0.14041\n",
      "[1124]\tvalidation_0-rmse:0.14039\n",
      "[1125]\tvalidation_0-rmse:0.14041\n",
      "[1126]\tvalidation_0-rmse:0.14040\n",
      "[1127]\tvalidation_0-rmse:0.14041\n",
      "[1128]\tvalidation_0-rmse:0.14039\n",
      "[1129]\tvalidation_0-rmse:0.14041\n",
      "[1130]\tvalidation_0-rmse:0.14039\n",
      "[1131]\tvalidation_0-rmse:0.14037\n",
      "[1132]\tvalidation_0-rmse:0.14037\n",
      "[1133]\tvalidation_0-rmse:0.14037\n",
      "[1134]\tvalidation_0-rmse:0.14037\n",
      "[1135]\tvalidation_0-rmse:0.14038\n",
      "[1136]\tvalidation_0-rmse:0.14039\n",
      "[1137]\tvalidation_0-rmse:0.14038\n",
      "[1138]\tvalidation_0-rmse:0.14037\n",
      "[1139]\tvalidation_0-rmse:0.14036\n",
      "[1140]\tvalidation_0-rmse:0.14036\n",
      "[1141]\tvalidation_0-rmse:0.14035\n",
      "[1142]\tvalidation_0-rmse:0.14033\n",
      "[1143]\tvalidation_0-rmse:0.14035\n",
      "[1144]\tvalidation_0-rmse:0.14036\n",
      "[1145]\tvalidation_0-rmse:0.14037\n",
      "[1146]\tvalidation_0-rmse:0.14036\n",
      "[1147]\tvalidation_0-rmse:0.14037\n",
      "[1148]\tvalidation_0-rmse:0.14038\n",
      "[1149]\tvalidation_0-rmse:0.14037\n",
      "[1150]\tvalidation_0-rmse:0.14037\n",
      "[1151]\tvalidation_0-rmse:0.14035\n",
      "[1152]\tvalidation_0-rmse:0.14037\n",
      "[1153]\tvalidation_0-rmse:0.14036\n",
      "[1154]\tvalidation_0-rmse:0.14037\n",
      "[1155]\tvalidation_0-rmse:0.14040\n",
      "[1156]\tvalidation_0-rmse:0.14041\n",
      "[1157]\tvalidation_0-rmse:0.14039\n",
      "[1158]\tvalidation_0-rmse:0.14039\n",
      "[1159]\tvalidation_0-rmse:0.14035\n",
      "[1160]\tvalidation_0-rmse:0.14034\n",
      "[1161]\tvalidation_0-rmse:0.14036\n",
      "[1162]\tvalidation_0-rmse:0.14036\n",
      "[1163]\tvalidation_0-rmse:0.14033\n",
      "[1164]\tvalidation_0-rmse:0.14036\n",
      "[1165]\tvalidation_0-rmse:0.14035\n",
      "[1166]\tvalidation_0-rmse:0.14035\n",
      "[1167]\tvalidation_0-rmse:0.14036\n",
      "[1168]\tvalidation_0-rmse:0.14035\n",
      "[1169]\tvalidation_0-rmse:0.14034\n",
      "[1170]\tvalidation_0-rmse:0.14036\n",
      "[1171]\tvalidation_0-rmse:0.14034\n",
      "[1172]\tvalidation_0-rmse:0.14027\n",
      "[1173]\tvalidation_0-rmse:0.14027\n",
      "[1174]\tvalidation_0-rmse:0.14031\n",
      "[1175]\tvalidation_0-rmse:0.14036\n",
      "[1176]\tvalidation_0-rmse:0.14035\n",
      "[1177]\tvalidation_0-rmse:0.14031\n",
      "[1178]\tvalidation_0-rmse:0.14032\n",
      "[1179]\tvalidation_0-rmse:0.14031\n",
      "[1180]\tvalidation_0-rmse:0.14031\n",
      "[1181]\tvalidation_0-rmse:0.14030\n",
      "[1182]\tvalidation_0-rmse:0.14028\n",
      "[1183]\tvalidation_0-rmse:0.14030\n",
      "[1184]\tvalidation_0-rmse:0.14030\n",
      "[1185]\tvalidation_0-rmse:0.14028\n",
      "[1186]\tvalidation_0-rmse:0.14028\n",
      "[1187]\tvalidation_0-rmse:0.14025\n",
      "[1188]\tvalidation_0-rmse:0.14025\n",
      "[1189]\tvalidation_0-rmse:0.14024\n",
      "[1190]\tvalidation_0-rmse:0.14024\n",
      "[1191]\tvalidation_0-rmse:0.14024\n",
      "[1192]\tvalidation_0-rmse:0.14024\n",
      "[1193]\tvalidation_0-rmse:0.14024\n",
      "[1194]\tvalidation_0-rmse:0.14020\n",
      "[1195]\tvalidation_0-rmse:0.14012\n",
      "[1196]\tvalidation_0-rmse:0.14011\n",
      "[1197]\tvalidation_0-rmse:0.14011\n",
      "[1198]\tvalidation_0-rmse:0.14010\n",
      "[1199]\tvalidation_0-rmse:0.14009\n",
      "[1200]\tvalidation_0-rmse:0.14009\n",
      "[1201]\tvalidation_0-rmse:0.14009\n",
      "[1202]\tvalidation_0-rmse:0.14007\n",
      "[1203]\tvalidation_0-rmse:0.14006\n",
      "[1204]\tvalidation_0-rmse:0.13998\n",
      "[1205]\tvalidation_0-rmse:0.13997\n",
      "[1206]\tvalidation_0-rmse:0.13996\n",
      "[1207]\tvalidation_0-rmse:0.13997\n",
      "[1208]\tvalidation_0-rmse:0.13997\n",
      "[1209]\tvalidation_0-rmse:0.13995\n",
      "[1210]\tvalidation_0-rmse:0.13994\n",
      "[1211]\tvalidation_0-rmse:0.13986\n",
      "[1212]\tvalidation_0-rmse:0.13985\n",
      "[1213]\tvalidation_0-rmse:0.13985\n",
      "[1214]\tvalidation_0-rmse:0.13985\n",
      "[1215]\tvalidation_0-rmse:0.13982\n",
      "[1216]\tvalidation_0-rmse:0.13980\n",
      "[1217]\tvalidation_0-rmse:0.13980\n",
      "[1218]\tvalidation_0-rmse:0.13979\n",
      "[1219]\tvalidation_0-rmse:0.13978\n",
      "[1220]\tvalidation_0-rmse:0.13977\n",
      "[1221]\tvalidation_0-rmse:0.13978\n",
      "[1222]\tvalidation_0-rmse:0.13978\n",
      "[1223]\tvalidation_0-rmse:0.13978\n",
      "[1224]\tvalidation_0-rmse:0.13977\n",
      "[1225]\tvalidation_0-rmse:0.13975\n",
      "[1226]\tvalidation_0-rmse:0.13975\n",
      "[1227]\tvalidation_0-rmse:0.13978\n",
      "[1228]\tvalidation_0-rmse:0.13978\n",
      "[1229]\tvalidation_0-rmse:0.13980\n",
      "[1230]\tvalidation_0-rmse:0.13980\n",
      "[1231]\tvalidation_0-rmse:0.13983\n",
      "[1232]\tvalidation_0-rmse:0.13982\n",
      "[1233]\tvalidation_0-rmse:0.13983\n",
      "[1234]\tvalidation_0-rmse:0.13982\n",
      "[1235]\tvalidation_0-rmse:0.13986\n",
      "[1236]\tvalidation_0-rmse:0.13987\n",
      "[1237]\tvalidation_0-rmse:0.13985\n",
      "[1238]\tvalidation_0-rmse:0.13987\n",
      "[1239]\tvalidation_0-rmse:0.13987\n",
      "[1240]\tvalidation_0-rmse:0.13987\n",
      "[1241]\tvalidation_0-rmse:0.13979\n",
      "[1242]\tvalidation_0-rmse:0.13979\n",
      "[1243]\tvalidation_0-rmse:0.13979\n",
      "[1244]\tvalidation_0-rmse:0.13978\n",
      "[1245]\tvalidation_0-rmse:0.13978\n",
      "[1246]\tvalidation_0-rmse:0.13980\n",
      "[1247]\tvalidation_0-rmse:0.13981\n",
      "[1248]\tvalidation_0-rmse:0.13982\n",
      "[1249]\tvalidation_0-rmse:0.13983\n",
      "[1250]\tvalidation_0-rmse:0.13981\n",
      "[1251]\tvalidation_0-rmse:0.13980\n",
      "[1252]\tvalidation_0-rmse:0.13978\n",
      "[1253]\tvalidation_0-rmse:0.13978\n",
      "[1254]\tvalidation_0-rmse:0.13977\n",
      "[1255]\tvalidation_0-rmse:0.13977\n",
      "[1256]\tvalidation_0-rmse:0.13975\n",
      "[1257]\tvalidation_0-rmse:0.13978\n",
      "[1258]\tvalidation_0-rmse:0.13981\n",
      "[1259]\tvalidation_0-rmse:0.13982\n",
      "[1260]\tvalidation_0-rmse:0.13983\n",
      "[1261]\tvalidation_0-rmse:0.13983\n",
      "[1262]\tvalidation_0-rmse:0.13986\n",
      "[1263]\tvalidation_0-rmse:0.13983\n",
      "[1264]\tvalidation_0-rmse:0.13983\n",
      "[1265]\tvalidation_0-rmse:0.13981\n",
      "[1266]\tvalidation_0-rmse:0.13980\n",
      "[1267]\tvalidation_0-rmse:0.13979\n",
      "[1268]\tvalidation_0-rmse:0.13980\n",
      "[1269]\tvalidation_0-rmse:0.13980\n",
      "[1270]\tvalidation_0-rmse:0.13980\n",
      "[1271]\tvalidation_0-rmse:0.13977\n",
      "[1272]\tvalidation_0-rmse:0.13980\n",
      "[1273]\tvalidation_0-rmse:0.13980\n",
      "[1274]\tvalidation_0-rmse:0.13979\n",
      "[1275]\tvalidation_0-rmse:0.13979\n",
      "[1276]\tvalidation_0-rmse:0.13978\n",
      "[1277]\tvalidation_0-rmse:0.13976\n",
      "[1278]\tvalidation_0-rmse:0.13979\n",
      "[1279]\tvalidation_0-rmse:0.13978\n",
      "[1280]\tvalidation_0-rmse:0.13977\n",
      "[1281]\tvalidation_0-rmse:0.13978\n",
      "[1282]\tvalidation_0-rmse:0.13975\n",
      "[1283]\tvalidation_0-rmse:0.13974\n",
      "[1284]\tvalidation_0-rmse:0.13973\n",
      "[1285]\tvalidation_0-rmse:0.13970\n",
      "[1286]\tvalidation_0-rmse:0.13971\n",
      "[1287]\tvalidation_0-rmse:0.13971\n",
      "[1288]\tvalidation_0-rmse:0.13969\n",
      "[1289]\tvalidation_0-rmse:0.13971\n",
      "[1290]\tvalidation_0-rmse:0.13972\n",
      "[1291]\tvalidation_0-rmse:0.13971\n",
      "[1292]\tvalidation_0-rmse:0.13971\n",
      "[1293]\tvalidation_0-rmse:0.13971\n",
      "[1294]\tvalidation_0-rmse:0.13970\n",
      "[1295]\tvalidation_0-rmse:0.13970\n",
      "[1296]\tvalidation_0-rmse:0.13969\n",
      "[1297]\tvalidation_0-rmse:0.13968\n",
      "[1298]\tvalidation_0-rmse:0.13968\n",
      "[1299]\tvalidation_0-rmse:0.13969\n",
      "[1300]\tvalidation_0-rmse:0.13973\n",
      "[1301]\tvalidation_0-rmse:0.13974\n",
      "[1302]\tvalidation_0-rmse:0.13974\n",
      "[1303]\tvalidation_0-rmse:0.13975\n",
      "[1304]\tvalidation_0-rmse:0.13975\n",
      "[1305]\tvalidation_0-rmse:0.13975\n",
      "[1306]\tvalidation_0-rmse:0.13975\n",
      "[1307]\tvalidation_0-rmse:0.13976\n",
      "[1308]\tvalidation_0-rmse:0.13978\n",
      "[1309]\tvalidation_0-rmse:0.13977\n",
      "[1310]\tvalidation_0-rmse:0.13977\n",
      "[1311]\tvalidation_0-rmse:0.13978\n",
      "[1312]\tvalidation_0-rmse:0.13978\n",
      "[1313]\tvalidation_0-rmse:0.13976\n",
      "[1314]\tvalidation_0-rmse:0.13976\n",
      "[1315]\tvalidation_0-rmse:0.13976\n",
      "[1316]\tvalidation_0-rmse:0.13975\n",
      "[1317]\tvalidation_0-rmse:0.13976\n",
      "[1318]\tvalidation_0-rmse:0.13977\n",
      "[1319]\tvalidation_0-rmse:0.13975\n",
      "[1320]\tvalidation_0-rmse:0.13973\n",
      "[1321]\tvalidation_0-rmse:0.13969\n",
      "[1322]\tvalidation_0-rmse:0.13972\n",
      "[1323]\tvalidation_0-rmse:0.13964\n",
      "[1324]\tvalidation_0-rmse:0.13962\n",
      "[1325]\tvalidation_0-rmse:0.13961\n",
      "[1326]\tvalidation_0-rmse:0.13961\n",
      "[1327]\tvalidation_0-rmse:0.13961\n",
      "[1328]\tvalidation_0-rmse:0.13961\n",
      "[1329]\tvalidation_0-rmse:0.13959\n",
      "[1330]\tvalidation_0-rmse:0.13960\n",
      "[1331]\tvalidation_0-rmse:0.13961\n",
      "[1332]\tvalidation_0-rmse:0.13953\n",
      "[1333]\tvalidation_0-rmse:0.13954\n",
      "[1334]\tvalidation_0-rmse:0.13953\n",
      "[1335]\tvalidation_0-rmse:0.13957\n",
      "[1336]\tvalidation_0-rmse:0.13957\n",
      "[1337]\tvalidation_0-rmse:0.13956\n",
      "[1338]\tvalidation_0-rmse:0.13959\n",
      "[1339]\tvalidation_0-rmse:0.13959\n",
      "[1340]\tvalidation_0-rmse:0.13957\n",
      "[1341]\tvalidation_0-rmse:0.13962\n",
      "[1342]\tvalidation_0-rmse:0.13960\n",
      "[1343]\tvalidation_0-rmse:0.13961\n",
      "[1344]\tvalidation_0-rmse:0.13962\n",
      "[1345]\tvalidation_0-rmse:0.13963\n",
      "[1346]\tvalidation_0-rmse:0.13955\n",
      "[1347]\tvalidation_0-rmse:0.13956\n",
      "[1348]\tvalidation_0-rmse:0.13958\n",
      "[1349]\tvalidation_0-rmse:0.13960\n",
      "[1350]\tvalidation_0-rmse:0.13959\n",
      "[1351]\tvalidation_0-rmse:0.13958\n",
      "[1352]\tvalidation_0-rmse:0.13958\n",
      "[1353]\tvalidation_0-rmse:0.13957\n",
      "[1354]\tvalidation_0-rmse:0.13958\n",
      "[1355]\tvalidation_0-rmse:0.13958\n",
      "[1356]\tvalidation_0-rmse:0.13958\n",
      "[1357]\tvalidation_0-rmse:0.13959\n",
      "[1358]\tvalidation_0-rmse:0.13958\n",
      "[1359]\tvalidation_0-rmse:0.13958\n",
      "[1360]\tvalidation_0-rmse:0.13958\n",
      "[1361]\tvalidation_0-rmse:0.13958\n",
      "[1362]\tvalidation_0-rmse:0.13953\n",
      "[1363]\tvalidation_0-rmse:0.13952\n",
      "[1364]\tvalidation_0-rmse:0.13952\n",
      "[1365]\tvalidation_0-rmse:0.13952\n",
      "[1366]\tvalidation_0-rmse:0.13952\n",
      "[1367]\tvalidation_0-rmse:0.13952\n",
      "[1368]\tvalidation_0-rmse:0.13951\n",
      "[1369]\tvalidation_0-rmse:0.13949\n",
      "[1370]\tvalidation_0-rmse:0.13951\n",
      "[1371]\tvalidation_0-rmse:0.13950\n",
      "[1372]\tvalidation_0-rmse:0.13948\n",
      "[1373]\tvalidation_0-rmse:0.13948\n",
      "[1374]\tvalidation_0-rmse:0.13947\n",
      "[1375]\tvalidation_0-rmse:0.13950\n",
      "[1376]\tvalidation_0-rmse:0.13950\n",
      "[1377]\tvalidation_0-rmse:0.13950\n",
      "[1378]\tvalidation_0-rmse:0.13950\n",
      "[1379]\tvalidation_0-rmse:0.13947\n",
      "[1380]\tvalidation_0-rmse:0.13949\n",
      "[1381]\tvalidation_0-rmse:0.13946\n",
      "[1382]\tvalidation_0-rmse:0.13945\n",
      "[1383]\tvalidation_0-rmse:0.13947\n",
      "[1384]\tvalidation_0-rmse:0.13946\n",
      "[1385]\tvalidation_0-rmse:0.13945\n",
      "[1386]\tvalidation_0-rmse:0.13946\n",
      "[1387]\tvalidation_0-rmse:0.13945\n",
      "[1388]\tvalidation_0-rmse:0.13945\n",
      "[1389]\tvalidation_0-rmse:0.13946\n",
      "[1390]\tvalidation_0-rmse:0.13945\n",
      "[1391]\tvalidation_0-rmse:0.13941\n",
      "[1392]\tvalidation_0-rmse:0.13941\n",
      "[1393]\tvalidation_0-rmse:0.13940\n",
      "[1394]\tvalidation_0-rmse:0.13942\n",
      "[1395]\tvalidation_0-rmse:0.13944\n",
      "[1396]\tvalidation_0-rmse:0.13944\n",
      "[1397]\tvalidation_0-rmse:0.13944\n",
      "[1398]\tvalidation_0-rmse:0.13946\n",
      "[1399]\tvalidation_0-rmse:0.13947\n",
      "[1400]\tvalidation_0-rmse:0.13947\n",
      "[1401]\tvalidation_0-rmse:0.13948\n",
      "[1402]\tvalidation_0-rmse:0.13948\n",
      "[1403]\tvalidation_0-rmse:0.13948\n",
      "[1404]\tvalidation_0-rmse:0.13950\n",
      "[1405]\tvalidation_0-rmse:0.13951\n",
      "[1406]\tvalidation_0-rmse:0.13952\n",
      "[1407]\tvalidation_0-rmse:0.13950\n",
      "[1408]\tvalidation_0-rmse:0.13947\n",
      "[1409]\tvalidation_0-rmse:0.13947\n",
      "[1410]\tvalidation_0-rmse:0.13941\n",
      "[1411]\tvalidation_0-rmse:0.13939\n",
      "[1412]\tvalidation_0-rmse:0.13939\n",
      "[1413]\tvalidation_0-rmse:0.13939\n",
      "[1414]\tvalidation_0-rmse:0.13939\n",
      "[1415]\tvalidation_0-rmse:0.13939\n",
      "[1416]\tvalidation_0-rmse:0.13941\n",
      "[1417]\tvalidation_0-rmse:0.13941\n",
      "[1418]\tvalidation_0-rmse:0.13941\n",
      "[1419]\tvalidation_0-rmse:0.13941\n",
      "[1420]\tvalidation_0-rmse:0.13940\n",
      "[1421]\tvalidation_0-rmse:0.13941\n",
      "[1422]\tvalidation_0-rmse:0.13945\n",
      "[1423]\tvalidation_0-rmse:0.13945\n",
      "[1424]\tvalidation_0-rmse:0.13943\n",
      "[1425]\tvalidation_0-rmse:0.13944\n",
      "[1426]\tvalidation_0-rmse:0.13942\n",
      "[1427]\tvalidation_0-rmse:0.13942\n",
      "[1428]\tvalidation_0-rmse:0.13941\n",
      "[1429]\tvalidation_0-rmse:0.13940\n",
      "[1430]\tvalidation_0-rmse:0.13941\n",
      "[1431]\tvalidation_0-rmse:0.13943\n",
      "[1432]\tvalidation_0-rmse:0.13941\n",
      "[1433]\tvalidation_0-rmse:0.13942\n",
      "[1434]\tvalidation_0-rmse:0.13941\n",
      "[1435]\tvalidation_0-rmse:0.13944\n",
      "[1436]\tvalidation_0-rmse:0.13942\n",
      "[1437]\tvalidation_0-rmse:0.13943\n",
      "[1438]\tvalidation_0-rmse:0.13942\n",
      "[1439]\tvalidation_0-rmse:0.13944\n",
      "[1440]\tvalidation_0-rmse:0.13944\n",
      "[1441]\tvalidation_0-rmse:0.13942\n",
      "[1442]\tvalidation_0-rmse:0.13942\n",
      "[1443]\tvalidation_0-rmse:0.13944\n",
      "[1444]\tvalidation_0-rmse:0.13949\n",
      "[1445]\tvalidation_0-rmse:0.13947\n",
      "[1446]\tvalidation_0-rmse:0.13951\n",
      "[1447]\tvalidation_0-rmse:0.13951\n",
      "[1448]\tvalidation_0-rmse:0.13951\n",
      "[1449]\tvalidation_0-rmse:0.13952\n",
      "[1450]\tvalidation_0-rmse:0.13952\n",
      "[1451]\tvalidation_0-rmse:0.13950\n",
      "[1452]\tvalidation_0-rmse:0.13953\n",
      "[1453]\tvalidation_0-rmse:0.13953\n",
      "[1454]\tvalidation_0-rmse:0.13955\n",
      "[1455]\tvalidation_0-rmse:0.13956\n",
      "[1456]\tvalidation_0-rmse:0.13960\n",
      "[1457]\tvalidation_0-rmse:0.13964\n",
      "[1458]\tvalidation_0-rmse:0.13963\n",
      "[1459]\tvalidation_0-rmse:0.13964\n",
      "[1460]\tvalidation_0-rmse:0.13961\n",
      "[1461]\tvalidation_0-rmse:0.13963\n",
      "[1462]\tvalidation_0-rmse:0.13965\n",
      "[1463]\tvalidation_0-rmse:0.13965\n",
      "[1464]\tvalidation_0-rmse:0.13966\n",
      "[1465]\tvalidation_0-rmse:0.13960\n",
      "[1466]\tvalidation_0-rmse:0.13957\n",
      "[1467]\tvalidation_0-rmse:0.13958\n",
      "[1468]\tvalidation_0-rmse:0.13957\n",
      "[1469]\tvalidation_0-rmse:0.13959\n",
      "[1470]\tvalidation_0-rmse:0.13958\n",
      "[1471]\tvalidation_0-rmse:0.13956\n",
      "[1472]\tvalidation_0-rmse:0.13958\n",
      "[1473]\tvalidation_0-rmse:0.13959\n",
      "[1474]\tvalidation_0-rmse:0.13959\n",
      "[1475]\tvalidation_0-rmse:0.13957\n",
      "[1476]\tvalidation_0-rmse:0.13957\n",
      "[1477]\tvalidation_0-rmse:0.13958\n",
      "[1478]\tvalidation_0-rmse:0.13961\n",
      "[1479]\tvalidation_0-rmse:0.13959\n",
      "[1480]\tvalidation_0-rmse:0.13958\n",
      "[1481]\tvalidation_0-rmse:0.13957\n",
      "[1482]\tvalidation_0-rmse:0.13960\n",
      "[1483]\tvalidation_0-rmse:0.13960\n",
      "[1484]\tvalidation_0-rmse:0.13958\n",
      "[1485]\tvalidation_0-rmse:0.13960\n",
      "[1486]\tvalidation_0-rmse:0.13960\n",
      "[1487]\tvalidation_0-rmse:0.13958\n",
      "[1488]\tvalidation_0-rmse:0.13957\n",
      "[1489]\tvalidation_0-rmse:0.13958\n",
      "[1490]\tvalidation_0-rmse:0.13957\n",
      "[1491]\tvalidation_0-rmse:0.13957\n",
      "[1492]\tvalidation_0-rmse:0.13958\n",
      "[1493]\tvalidation_0-rmse:0.13958\n",
      "[1494]\tvalidation_0-rmse:0.13957\n",
      "[1495]\tvalidation_0-rmse:0.13950\n",
      "[1496]\tvalidation_0-rmse:0.13950\n",
      "[1497]\tvalidation_0-rmse:0.13951\n",
      "[1498]\tvalidation_0-rmse:0.13950\n",
      "[1499]\tvalidation_0-rmse:0.13949\n",
      "[1500]\tvalidation_0-rmse:0.13948\n",
      "[1501]\tvalidation_0-rmse:0.13942\n",
      "[1502]\tvalidation_0-rmse:0.13942\n",
      "[1503]\tvalidation_0-rmse:0.13945\n",
      "[1504]\tvalidation_0-rmse:0.13946\n",
      "[1505]\tvalidation_0-rmse:0.13947\n",
      "[1506]\tvalidation_0-rmse:0.13948\n",
      "[1507]\tvalidation_0-rmse:0.13952\n",
      "[1508]\tvalidation_0-rmse:0.13952\n",
      "[1509]\tvalidation_0-rmse:0.13952\n",
      "[1510]\tvalidation_0-rmse:0.13954\n",
      "[1511]\tvalidation_0-rmse:0.13952\n",
      "Stopping. Best iteration:\n",
      "[1411]\tvalidation_0-rmse:0.13939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the final model with full dataset\n",
    "final_lasso = Lasso(random_state=0, \n",
    "        max_iter=50000, \n",
    "        alpha=0.00042).fit(X, target_y)\n",
    "final_ridge = Ridge(alpha=10).fit(X, target_y)\n",
    "final_svr = SVR(C=5, epsilon=0.001, gamma=0.0001).fit(X, target_y)\n",
    "final_xgb = xgb.fit(x_train, y_train, eval_set=eval_set, early_stopping_rounds=100, eval_metric='rmse')\n",
    "final_stacked = stacked.fit(np.array(X), np.array(target_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction result\n",
    "pred_xgb = final_xgb.predict(X_test)\n",
    "pred_lasso = final_lasso.predict(X_test)\n",
    "pred_ridge = final_ridge.predict(X_test)\n",
    "pred_svr = final_svr.predict(X_test)\n",
    "pred_stacked = final_stacked.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine final result and create submission file\n",
    "y_pred = 0.4 * pred_stacked + 0.4 * pred_lasso + 0.0 * pred_ridge + 0.0 * pred_svr + 0.2 * pred_xgb\n",
    "y_final_test = np.expm1(y_pred)\n",
    "\n",
    "# submission\n",
    "test_data['SalePrice'] = y_final_test\n",
    "submit = ['SalePrice', 'Id']\n",
    "submission = test_data[[c for c in test_data.columns if c in submit]]\n",
    "submission.to_csv('./data/TeamJarvisFinal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}