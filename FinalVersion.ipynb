{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from catboost import Pool, cv, CatBoostRegressor\n",
    "from scipy.special import boxcox1p\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LassoCV, Lasso, RidgeCV, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train_data['Training'] = 1\n",
    "test_data['Training'] = 0\n",
    "numerical_features = train_data.dtypes[train_data.dtypes != 'object'].index.values\n",
    "categorical_features = train_data.dtypes[train_data.dtypes == 'object'].index.values\n",
    "submit = ['SalePrice', 'Id']\n",
    "significant_columns_cat = ['Neighborhood', 'ExterQual', 'BsmtQual', 'KitchenQual', 'GarageFinish',\n",
    " 'FireplaceQu', 'Foundation', 'GarageType', 'BsmtFinType1', 'HeatingQC',\n",
    " 'MasVnrType', 'BsmtExposure', 'SaleCondition', 'Exterior1st', 'Exterior2nd',\n",
    " 'SaleType', 'MSZoning', 'HouseStyle', 'GarageQual', 'GarageCond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# remove outliers\n",
    "# Remove these outliers actually yielded worse result, so remove them for now\n",
    "# LotFrontage > 300\n",
    "# train_data = train_data.drop(train_data[train_data['LotFrontage']>300].index)\n",
    "# LotArea > 100000\n",
    "# train_data = train_data.drop(train_data[train_data['LotArea']>100000].index)\n",
    "# BsmtFinSF1 > 4000\n",
    "# train_data = train_data.drop(train_data[train_data['BsmtFinSF1']>4000].index)\n",
    "# GrLivArea > 4500\n",
    "# train_data = train_data.drop(train_data[train_data['GrLivArea']>4500].index)\n",
    "# TotalBsmtSF > 5000\n",
    "# train_data = train_data.drop(train_data[train_data['TotalBsmtSF']>5000].index)\n",
    "# OpenPorchSF > 500\n",
    "# train_data = train_data.drop(train_data[train_data['OpenPorchSF']>500].index)\n",
    "# 1stFlrSF > 4000\n",
    "# train_data = train_data.drop(train_data[train_data['1stFlrSF']>4000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat training and testing\n",
    "y = train_data['SalePrice']\n",
    "all_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n",
    "# fill categoricals\n",
    "categoricals = all_data[categorical_features]\n",
    "categoricals['MSZoning'] = categoricals['MSZoning'].fillna(categoricals['MSZoning'].mode()[0])\n",
    "categoricals.fillna('None', inplace=True)\n",
    "all_data[categorical_features] = categoricals\n",
    "\n",
    "# fill in numeric\n",
    "all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].apply(lambda x: x.fillna(x.median()))\n",
    "all_data.fillna(0, inplace=True)\n",
    "\n",
    "# select significant columns\n",
    "significant_columns = [*significant_columns_cat, *numerical_features]\n",
    "all_data = all_data[significant_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "# convert non-categorical to categorical\n",
    "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
    "all_data['OverallCond'] = all_data['OverallCond'].apply(str)\n",
    "\n",
    "# add in more features\n",
    "all_data['TotalSF'] = all_data['GrLivArea'] + all_data['TotalBsmtSF']\n",
    "all_data['Bathrooms'] = all_data['BsmtFullBath'] + all_data['FullBath'] + (all_data['BsmtHalfBath'] + all_data['HalfBath']) * 0.5\n",
    "all_data['QualSF'] = all_data['TotalSF'] * all_data['OverallQual']\n",
    "all_data['HasPool'] = all_data['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasGarage'] = all_data['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasRemod'] = (all_data['YearBuilt'] - all_data['YearRemodAdd']).apply(lambda x: 1 if x != 0 else 0)\n",
    "all_data['Has3SsnPorch'] = all_data['3SsnPorch'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasLowQualFin'] = all_data['LowQualFinSF'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['Age'] = all_data['YrSold'] - all_data['YearRemodAdd']\n",
    "all_data['IsNew'] = (all_data['YrSold'] - all_data['YearBuilt']).apply(lambda x: 1 if x == 0 else 0)\n",
    "all_data['TotalPorch'] = all_data['OpenPorchSF'] + all_data['EnclosedPorch'] + all_data['3SsnPorch'] + all_data['ScreenPorch']\n",
    "all_data['HasPorch'] = all_data['TotalPorch'].apply(lambda x: 1 if x > 0 else 0)\n",
    "all_data['HasFireplace'] = all_data['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# binning\n",
    "all_data['OpenPorchSF'] = pd.cut(all_data['OpenPorchSF'], [0, 5, 100, 300, 1000], include_lowest=True, labels=False)\n",
    "all_data['OpenPorchSF'] = all_data['OpenPorchSF'].apply(str)\n",
    "all_data['EnclosedPorch'] = pd.cut(all_data['EnclosedPorch'], [0, 5, 100, 250, 1000], include_lowest=True, labels=False)\n",
    "all_data['EnclosedPorch'] = all_data['EnclosedPorch'].apply(str)\n",
    "all_data['ScreenPorch'] = pd.cut(all_data['ScreenPorch'], [0, 5, 200, 1000], include_lowest=True, labels=False)\n",
    "all_data['ScreenPorch'] = all_data['ScreenPorch'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping a few columns\n",
    "to_drop = ['MoSold', 'PoolArea', 'GarageYrBlt', '3SsnPorch', 'YearRemodAdd', 'LowQualFinSF']\n",
    "all_data.drop(columns=to_drop, inplace=True)\n",
    "# drop saleprice\n",
    "all_data.drop(columns='SalePrice', inplace=True)\n",
    "\n",
    "# redefine categoricals\n",
    "numerical_features = all_data.dtypes[all_data.dtypes != 'object'].index.values\n",
    "categorical_features = all_data.dtypes[all_data.dtypes == 'object'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform features based on skewness\n",
    "skewness_cap = 2 # can change this number around a bit\n",
    "# define ignored features\n",
    "ignored_features = ['HasPool', 'HasGarage', 'HasRemod', 'Has3SsnPorch', 'HasLowQualFin', 'IsNew', 'HasPorch']\n",
    "# find skewness\n",
    "skewness = all_data[numerical_features].apply(lambda x: st.skew(x)).sort_values(ascending=False)\n",
    "skewness_features = skewness[abs(skewness) > skewness_cap].index\n",
    "skewness_features = [f for f in skewness_features if f not in ignored_features]\n",
    "# box-cox transform\n",
    "for col in skewness_features:\n",
    "    all_data[col] = boxcox1p(all_data[col], st.boxcox_normmax(all_data[col] + 1))\n",
    "\n",
    "# Show result\n",
    "adjusted_skewness = all_data[skewness_features].apply(lambda x: st.skew(x))\n",
    "\n",
    "skewness_compare = pd.DataFrame()\n",
    "skewness_compare['Features'] = skewness_features\n",
    "skewness_compare['Original'] = skewness[skewness_features].values\n",
    "skewness_compare['Adjusted'] = adjusted_skewness.values\n",
    "skewness_compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process categoricals\n",
    "all_data = pd.get_dummies(data=all_data)\n",
    "\n",
    "# Split up the dataset\n",
    "train_set = all_data.loc[all_data['Training'] == 1]\n",
    "test_set = all_data.loc[all_data['Training'] == 0]\n",
    "\n",
    "# obtain X & y\n",
    "\n",
    "y_log = np.log1p(y)\n",
    "target_y = y_log\n",
    "\n",
    "omit = ['SalePrice', 'Id', 'Training']\n",
    "X = train_set[[c for c in train_set.columns if c not in omit]]\n",
    "X_test = test_set[[c for c in test_set.columns if c not in omit]]\n",
    "\n",
    "# further split into validation set and training set\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(X, target_y, test_size=0.1, random_state=27)\n",
    "eval_set = [(x_validation, y_validation)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to True to run all CVs\n",
    "run_full_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lasso model and use cv to find best alpha\n",
    "alphas = np.arange(1e-5, 1e-2, 1e-5)\n",
    "if run_full_tuning:\n",
    "    lasso_reg = LassoCV(cv=5, \n",
    "        random_state=0, \n",
    "        max_iter=50000, \n",
    "        alphas=alphas).fit(X, target_y)\n",
    "    best_alpha = lasso_reg.alpha_ # Lasso alpha: 0.00042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ridge model and use cv to find best alpha\n",
    "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 20, 30, 50, 75, 100]\n",
    "if run_full_tuning:\n",
    "    ridge_reg = RidgeCV(cv=5, \n",
    "        alphas=ridge_alphas).fit(X, target_y)\n",
    "\n",
    "    best_ridge_alpha = ridge_reg.alpha_ # Ridge alpha: 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR CV Grid Search\n",
    "if run_full_tuning:\n",
    "    svr_model = SVR()\n",
    "\n",
    "    clf = GridSearchCV(svr_model,\n",
    "        {'C': [1, 5, 10, 20],\n",
    "        'epsilon': [0.1, 0.01, 0.001],\n",
    "        'gamma': [1, 0.1, 0.001, 0.0001, 0.00001]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_svr_c = clf.best_params_['C']\n",
    "    best_svr_epsilon = clf.best_params_['epsilon']\n",
    "    best_svr_gamma = clf.best_params_['gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for xgb\n",
    "if run_full_tuning:\n",
    "    xgb_model = XGBRegressor(n_jobs=1, gamma=0, n_estimators=5000)\n",
    "    clf = GridSearchCV(xgb_model,\n",
    "        {'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 4, 5, 6]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_rate_xgb = clf.best_params_['learning_rate']\n",
    "    best_depth_xgb = clf.best_params_['max_depth']\n",
    "\n",
    "    xgb_model = XGBRegressor(n_jobs=1, gamma=0, n_estimators=5000, learning_rate=best_rate_xgb, max_depth=best_depth_xgb)\n",
    "    clf = GridSearchCV(xgb_model,\n",
    "        {'subsample': [0.5, 0.8, 1],\n",
    "        'colsample_bytree': [0.5, 0.8, 1]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_subsample_xgb = clf.best_params_['subsample']\n",
    "    best_colsample_bytree_xgb = clf.best_params_['colsample_bytree']\n",
    "\n",
    "    xgb_model = XGBRegressor(n_jobs=1, \n",
    "        gamma=0, \n",
    "        n_estimators=5000, \n",
    "        learning_rate=best_rate_xgb, \n",
    "        max_depth=best_depth_xgb,\n",
    "        subsample=best_subsample_xgb,\n",
    "        colsample_bytree=best_colsample_bytree_xgb)\n",
    "    clf = GridSearchCV(xgb_model,\n",
    "        {'reg_alpha': [0.5, 0.7, 0.9],\n",
    "        'reg_lambda': [0.5, 0.6, 0.8]\n",
    "        }, verbose=1, n_jobs=1)\n",
    "    clf.fit(X, target_y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "    best_alpha_xgb = clf.best_params_['reg_alpha']\n",
    "    best_lambda_xgb = clf.best_params_['reg_lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Models\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(random_state=0, \n",
    "        max_iter=50000, \n",
    "        alpha=0.00042)) \n",
    "\n",
    "xgb = XGBRegressor(n_jobs=1, \n",
    "    gamma=0, \n",
    "    n_estimators=5000, \n",
    "    learning_rate=0.01, \n",
    "    max_depth=3,\n",
    "    subsample=0.7,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.6,\n",
    "    scale_pos_weight=1,\n",
    "    min_child_weight=0,\n",
    "    random_state=27,\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.7)\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(), Ridge(alpha=10))\n",
    "\n",
    "svr = make_pipeline(RobustScaler(), SVR(C=5, epsilon=0.001, gamma=0.0001))\n",
    "\n",
    "stacked = StackingCVRegressor(regressors=(lasso, xgb, ridge, svr),\n",
    "    meta_regressor=xgb,\n",
    "    use_features_in_secondary=True,\n",
    "    random_state=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all models\n",
    "def rmse(y1, y2):\n",
    "    return np.sqrt(metrics.mean_squared_error(y1, y2))\n",
    "\n",
    "good_weights = pd.DataFrame(columns=['Lasso', 'XGB', 'Ridge', 'SVR', 'Stacked', 'Error'])\n",
    "\n",
    "if run_full_tuning:\n",
    "    splits = 5\n",
    "    kf = KFold(n_splits=splits)\n",
    "    split_count = 1\n",
    "    \n",
    "    for train, test in kf.split(x_train):\n",
    "        print('Calculating in split #', split_count)\n",
    "        \n",
    "        train_x = x_train.iloc[train, :]\n",
    "        test_x = x_train.iloc[test, :]\n",
    "\n",
    "        train_y = y_train.iloc[train]\n",
    "        test_y = y_train.iloc[test]\n",
    "\n",
    "        lasso_train = lasso.fit(train_x, train_y)\n",
    "        ridge_train = ridge.fit(train_x, train_y)\n",
    "        svr_train = svr.fit(train_x, train_y)\n",
    "        xgb_train = xgb.fit(train_x, train_y, eval_set=eval_set, early_stopping_rounds=100, eval_metric='rmse')\n",
    "        stacked_train = stacked.fit(np.array(train_x), np.array(train_y))\n",
    "\n",
    "        pred_lasso = lasso_train.predict(test_x)\n",
    "        pred_xgb = xgb_train.predict(test_x)\n",
    "        pred_ridge = ridge_train.predict(test_x)\n",
    "        pred_svr = svr_train.predict(test_x)\n",
    "        pred_stacked = stacked_train.predict(np.array(test_x))\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for lasso_weight in np.arange(0, 1, 0.05):\n",
    "            xgb_weights = np.arange(0, 1 - lasso_weight, 0.05)\n",
    "            for xgb_weight in xgb_weights:\n",
    "                ridge_weights = np.arange(0, 1 - lasso_weight - xgb_weight, 0.05)\n",
    "                for ridge_weight in ridge_weights:\n",
    "                    svr_weights = np.arange(0, 1 - lasso_weight - xgb_weight - ridge_weight, 0.05)\n",
    "                    for svr_weight in svr_weights:\n",
    "                        stacked_weight = 1 - lasso_weight - xgb_weight - ridge_weight - svr_weight\n",
    "                        \n",
    "                        y_pred_val = (stacked_weight * pred_stacked + \n",
    "                            xgb_weight * pred_xgb + \n",
    "                            lasso_weight * pred_lasso + \n",
    "                            svr_weight * pred_svr + \n",
    "                            ridge_weight * pred_ridge)\n",
    "                        \n",
    "                        error = rmse(test_y, y_pred_val) / 5 # average\n",
    "                        if split_count == 1:\n",
    "                            good_weights = good_weights.append({\n",
    "                                'Lasso': lasso_weight,\n",
    "                                'XGB': xgb_weight,\n",
    "                                'Ridge': ridge_weight,\n",
    "                                'SVR': svr_weight,\n",
    "                                'Stacked': stacked_weight,\n",
    "                                'Error': error\n",
    "                                }, ignore_index=True)\n",
    "                        else:\n",
    "                            good_weights.iloc[count]['Error'] = good_weights.iloc[count]['Error'] + error\n",
    "\n",
    "                        count = count + 1\n",
    "        print('Split #', split_count, 'done')\n",
    "        split_count = split_count + 1\n",
    "    good_weights = good_weights.sort_values('Error')\n",
    "\n",
    "    good_weights.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model with full dataset\n",
    "final_lasso = Lasso(random_state=0, \n",
    "        max_iter=50000, \n",
    "        alpha=0.00042).fit(X, target_y)\n",
    "final_ridge = Ridge(alpha=10).fit(X, target_y)\n",
    "final_svr = SVR(C=5, epsilon=0.001, gamma=0.0001).fit(X, target_y)\n",
    "final_xgb = xgb.fit(x_train, y_train, eval_set=eval_set, early_stopping_rounds=100, eval_metric='rmse')\n",
    "final_stacked = stacked.fit(np.array(X), np.array(target_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction result\n",
    "pred_xgb = final_xgb.predict(X_test)\n",
    "pred_lasso = final_lasso.predict(X_test)\n",
    "pred_ridge = final_ridge.predict(X_test)\n",
    "pred_svr = final_svr.predict(X_test)\n",
    "pred_stacked = final_stacked.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine final result and create submission file\n",
    "y_pred = 0.4 * pred_stacked + 0.4 * pred_lasso + 0.0 * pred_ridge + 0.0 * pred_svr + 0.2 * pred_xgb\n",
    "y_final_test = np.expm1(y_pred)\n",
    "\n",
    "# submission\n",
    "test_data['SalePrice'] = y_final_test\n",
    "submit = ['SalePrice', 'Id']\n",
    "submission = test_data[[c for c in test_data.columns if c in submit]]\n",
    "submission.to_csv('./data/TeamJarvisFinal.csv', index=False)"
   ]
  }
 ]
}